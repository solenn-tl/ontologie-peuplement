{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des resources RDF des mentions de parcelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import re\n",
    "from rdflib import Graph, Literal, Namespace, RDF, URIRef, BNode\n",
    "from rdflib.namespace import XSD, DCTERMS, PROV, SKOS, RDFS\n",
    "from functions import *\n",
    "from namespaces import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lecture des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMUNE = 'Gentilly'\n",
    "matrices_metada = {\n",
    "    \"MAT_1813\": {\n",
    "        \"PLAN\": \"1811\",\n",
    "        \"MATRICE_ID\": \"MAT_B_NB_1813\",\n",
    "        \"MATRICE_START\": \"1813\",\n",
    "        \"MATRICE_END\": \"1835\"\n",
    "    },\n",
    "    \"MAT_1836\": {\n",
    "        \"PLAN\": \"1811\",\n",
    "        \"MATRICE_ID\": \"MAT_NB_1836\",\n",
    "        \"MATRICE_START\": \"1836\",\n",
    "        \"MATRICE_END\": \"1847\"\n",
    "    },\n",
    "    \"MAT_1848\": {\n",
    "        \"PLAN\": \"1845\",\n",
    "        \"MATRICE_ID\": \"MAT_NB_1848\",\n",
    "        \"MATRICE_START\": \"1848\",\n",
    "        \"MATRICE_END\": \"1860\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/workspaces/ontologie-peuplement/\"  #/home/STual/KG-cadastre/\n",
    "\n",
    "PATH = ROOT + \"data/gentilly/MAT_1813.csv\"\n",
    "mat1813 = pd.read_csv(PATH,header=0)\n",
    "PATH = ROOT + \"data/gentilly/MAT_1836.csv\"\n",
    "mat1836 = pd.read_csv(PATH,header=0)\n",
    "PATH = ROOT + \"data/gentilly/MAT_1848.csv\"\n",
    "mat1848 = pd.read_csv(PATH,header=0)\n",
    "\n",
    "OUTPUT_FOLDER_PATH = ROOT + \"data/rdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1813['registre'] = 'MAT_1813'\n",
    "mat1836['registre'] = 'MAT_1836'\n",
    "mat1848['registre'] = 'MAT_1848'\n",
    "\n",
    "matrices = pd.concat([mat1813, mat1836, mat1848])\n",
    "matrices = matrices.reset_index(drop=True)\n",
    "print(matrices.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propriétaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open three json files\n",
    "with open(\"/home/STual/KG-cadastre/data/gentilly/structured_owners_ok.json\") as f:\n",
    "    data_owner_ok = json.load(f)\n",
    "with open(\"/home/STual/KG-cadastre/data/gentilly/structured_owners_nok1.json\") as f:\n",
    "    data_owner_nok1 = json.load(f)\n",
    "with open(\"/home/STual/KG-cadastre/data/gentilly/structured_owners_nok2.json\") as f:\n",
    "    data_owner_nok2 = json.load(f)\n",
    "\n",
    "#concatenate the three json files\n",
    "data_owners = data_owner_ok + data_owner_nok1 + data_owner_nok2\n",
    "\n",
    "#read as df\n",
    "owners_df = pd.DataFrame(data_owners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oregistre = []\n",
    "otype_folio = []\n",
    "ofolio = []\n",
    "o_groupe_cf = []\n",
    "o_transcription = []\n",
    "\n",
    "for row in owners_df.iterrows():\n",
    "    cell_info = row[1]['cell']\n",
    "    oregistre.append(cell_info['registre'])\n",
    "    otype_folio.append(cell_info['type_folio'])\n",
    "    ofolio.append(cell_info['folio'])\n",
    "    o_groupe_cf.append(cell_info['groupe_cf'])\n",
    "    o_transcription.append(cell_info['transcription'])\n",
    "\n",
    "owners_df['registre'] = oregistre\n",
    "owners_df['type_folio'] = otype_folio\n",
    "owners_df['folio'] = ofolio\n",
    "owners_df['groupe_cf'] = o_groupe_cf\n",
    "owners_df['transcription'] = o_transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Création des pages\n",
    "- rdf:type rico:Instanciation : instance numérisée d'une page de registre\n",
    "- rdf:type rico:Record => concept de la page de registre, fait le lien avec le registre (concept, RecordSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select distinct values in th colum Image\n",
    "images = matrices[['registre','Image']].drop_duplicates()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RDF graph\n",
    "g = Graph()\n",
    "\n",
    "g.bind('cad', cad)\n",
    "g.bind('add', add)\n",
    "g.bind('source', srcuri)\n",
    "g.bind('mlclasse', mlclasse)\n",
    "g.bind('activity', cad_act)\n",
    "\n",
    "g.bind('rico', rico)\n",
    "g.bind('fpo', fpo)\n",
    "g.bind('time',time)\n",
    "\n",
    "for index, row in images.iterrows():\n",
    "    img = row['Image']\n",
    "    MATRICE_ID = matrices_metada[row['registre']][\"MATRICE_ID\"]\n",
    "    json = parse_record_id(img)\n",
    "    subject_uri = URIRef(srcuri + f\"{img}\")\n",
    "    g.add((subject_uri, RDF.type, rico.Instanciation))\n",
    "    g.add((subject_uri, rico.identifier, Literal(img)))\n",
    "    mlClasseNode = BNode()\n",
    "    g.add((subject_uri, cad.hasClasse, mlClasseNode))\n",
    "    g.add((mlClasseNode, cad.hasClasseValue, URIRef(mlclasse + f\"MATMainTable\")))\n",
    "    g.add((mlClasseNode, PROV.wasGeneratedBy, URIRef(cad_act + f\"0001\")))\n",
    "    folder_end = img.rfind('_')\n",
    "    g.add((subject_uri,rico.isOrWasDigitalInstanciationOf,URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{img}_page\")))\n",
    "\n",
    "    subject_uri_record = URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{row['Image']}_page\")\n",
    "    g.add((subject_uri_record, RDF.type, rico.Record))\n",
    "    g.add((subject_uri_record, rico.isOrWasIncludedIn, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}\")))\n",
    "\n",
    "print(g.serialize(format='turtle'))\n",
    "#write g into a .ttl file\n",
    "g.serialize(destination=f\"{OUTPUT_FOLDER_PATH}/{COMMUNE}_sources_pages.ttl\", format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Folios\n",
    "- Pré-traitement des colonnes *Num_Folio*, *Tiré de* et *Porté à*\n",
    "- Création des objets \"Folios\" à partir de la colonne *Num_Folio* et des colonnes *Tiré de* et *Porté à* (manquants)\n",
    "- Création des objets spéciaux mentionnés dans les colonnes destinées aux folios (reste, construction nouvelle, ruine etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import parse_record_id, cleanNumFolio\n",
    "\n",
    "#Clean columns Num_Folio, Tire_de, Porte_a\n",
    "clean_folio, clean_tire_de, clean_porte_a = [], [], []\n",
    "symbols = [\",\", \"→\", \".\",\" \",\";\",\"&\"]\n",
    "\n",
    "for index, row in matrices.iterrows():\n",
    "    clean_folio.append(cleanNumFolio(row[\"Num_Folio\"],symbols))\n",
    "    clean_tire_de.append(cleanNumFolio(row[\"Tiré de_treated\"],symbols))\n",
    "    clean_porte_a.append(cleanNumFolio(row[\"Porté à_treated\"],symbols))\n",
    "\n",
    "# Create new columns containing the cleaned values\n",
    "matrices['Num_Folio_clean'] = clean_folio\n",
    "matrices['Tire_de_clean'] = clean_tire_de\n",
    "matrices['Porte_a_clean'] = clean_porte_a\n",
    "\n",
    "matrices['Num_Folio_clean'] = matrices['Num_Folio_clean'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_porte_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using matrices, create new df named folios containing all lines of matrices where register = MAT_1836 and MAT_1848. For register=MAT_1813, remove the lines where type_CF = \"Bâti\"\n",
    "folios = matrices[(matrices['registre'] == 'MAT_1836') | (matrices['registre'] == 'MAT_1848') | ((matrices['registre'] == 'MAT_1813') & (matrices['Type_CF'] != 'Bâti'))]\n",
    "folios.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe from sources with columns \"Num_Folio\" and \"Image\" containing only distinct rows\n",
    "folios_pages = folios[[\"Num_Folio_clean\",\"Alt_Num_CF\",\"Image\",\"registre\"]].drop_duplicates(subset=[\"Num_Folio_clean\",\"Alt_Num_CF\",\"Image\",\"registre\"]).reset_index(drop=True)\n",
    "display(folios_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RDF graph\n",
    "g = Graph()\n",
    "\n",
    "g.bind('source', srcuri)\n",
    "g.bind('srctype', srctype)\n",
    "g.bind('cad', cad)\n",
    "g.bind('add', add)\n",
    "g.bind('rico', rico)\n",
    "g.bind('fpo', fpo)\n",
    "g.bind('time',time)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in folios_pages.iterrows():\n",
    "    json = parse_record_id(row['Image'])\n",
    "    MATRICE_ID = matrices_metada[row['registre']][\"MATRICE_ID\"]\n",
    "\n",
    "    subject_uri = URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}_{str(row['Num_Folio_clean'])}\")\n",
    "    g.add((subject_uri, RDF.type, rico.RecordPart))\n",
    "    g.add((subject_uri, cad.isSourceType, URIRef(srctype.Folio)))\n",
    "    g.add((subject_uri, cad.hasNumFolio, Literal(row[\"Num_Folio_clean\"],datatype=XSD.string)))\n",
    "    g.add((subject_uri, rico.isOrWasConstituentOf,URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{row['Image']}_page\")))\n",
    "\n",
    "    if not pd.isna(row['Alt_Num_CF']):\n",
    "        g.add((subject_uri, cad.hasAlternativeNumFolio, Literal(int(row[\"Alt_Num_CF\"]),datatype=XSD.string)))\n",
    "\n",
    "print(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des folios issus de \"Tiré de\" et \"Porté à\" qui ne sont pas dans la colonne 'Num_Folios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "for index, row in folios.iterrows():\n",
    "    if row['Tire_de_clean'] != 'EMPTY':\n",
    "        ls = row['Tire_de_clean'].split(\";\")\n",
    "        for l in ls:\n",
    "            if any(num.isdigit() for num in l) and 'omission' not in l:\n",
    "                MATRICE_ID = matrices_metada[row['registre']][\"MATRICE_ID\"]\n",
    "\n",
    "                subject_uri = URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}_{str(l)}\")\n",
    "                g.add((subject_uri, RDF.type, rico.RecordPart))\n",
    "                g.add((subject_uri, cad.isSourceType, URIRef(srctype.Folio)))\n",
    "                g.add((subject_uri, cad.hasNumFolio, Literal(l,datatype=XSD.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "for index, row in folios.iterrows():\n",
    "    if row['Porte_a_clean'] != 'EMPTY':\n",
    "        ls = row['Porte_a_clean'].split(\";\")\n",
    "        for l in ls:\n",
    "            #test if str has digit\n",
    "            if any(num.isdigit() for num in l) and 'omission' not in l:\n",
    "                MATRICE_ID = matrices_metada[row['registre']][\"MATRICE_ID\"]\n",
    "\n",
    "                subject_uri = URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}_{str(l)}\")\n",
    "                g.add((subject_uri, RDF.type, rico.RecordPart))\n",
    "                g.add((subject_uri, cad.isSourceType, URIRef(srctype.Folio)))\n",
    "                g.add((subject_uri, cad.hasNumFolio, Literal(l,datatype=XSD.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(destination=f\"{OUTPUT_FOLDER_PATH}/{COMMUNE}_sources_folios.ttl\", format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the column as a new DataFrame\n",
    "addresses = matrices[['registre','Lieu-dit_treated','Lieu-dit_type']].copy().drop_duplicates().reset_index(drop=True)\n",
    "addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipart_addresses_street = []\n",
    "multipart_addresses_street_number = []\n",
    "multipart_addresses_street_type = []\n",
    "multipart_addresses_street_number_type = []\n",
    "\n",
    "\n",
    "for index, row in addresses.iterrows():\n",
    "    tag = str(row[\"Lieu-dit_treated\"])\n",
    "    if ';' in tag:\n",
    "        add = tag.split(\";\")\n",
    "        add_street_or_district = add[0]\n",
    "        add_num_or_part = add[1]\n",
    "\n",
    "        multipart_addresses_street.append(add_street_or_district)\n",
    "        multipart_addresses_street_number.append(add_num_or_part)\n",
    "\n",
    "        #test if digit\n",
    "        if any(num.isdigit() for num in add_num_or_part):\n",
    "            multipart_addresses_street_type.append('Thoroughfare')\n",
    "            multipart_addresses_street_number_type.append('StreetNumber')\n",
    "        else:\n",
    "            multipart_addresses_street_type.append('District')\n",
    "            multipart_addresses_street_number_type.append('Undefined')\n",
    "\n",
    "    else:\n",
    "        multipart_addresses_street.append('')\n",
    "        multipart_addresses_street_number.append('')\n",
    "        multipart_addresses_street_type.append('')\n",
    "        multipart_addresses_street_number_type.append('')\n",
    "\n",
    "addresses['part_street_district'] = multipart_addresses_street\n",
    "addresses['part_street_number'] = multipart_addresses_street_number\n",
    "addresses['part_street_district_type'] = multipart_addresses_street_type\n",
    "addresses['part_street_number_type'] = multipart_addresses_street_number_type\n",
    "\n",
    "#assign a distinct uuid for each group of rows with same values in Lieu-dit_treated and registre\n",
    "addresses['address_uuid'] = [uuid.uuid4() for _ in range(len(addresses))]\n",
    "\n",
    "addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Create a new column 'part_street_district_uuid'\n",
    "addresses['part_street_district_uuid'] = None\n",
    "\n",
    "# Create a dictionary to store the uuid for each unique part_street_district\n",
    "uuid_dict = {}\n",
    "\n",
    "# Iterate over the DataFrame\n",
    "for i, row in addresses.iterrows():\n",
    "    if row['part_street_district'] != '':\n",
    "        # Check if the part_street_district value is equal to one of the Lieu-dit_treated values\n",
    "        if row['part_street_district'] in addresses['Lieu-dit_treated'].values:\n",
    "            # If yes, set the part_street_district_uuid to the uuid of the retrieved Lieu-dit_treated\n",
    "            addresses.loc[i, 'part_street_district_uuid'] = addresses.loc[addresses['Lieu-dit_treated'] == row['part_street_district'], 'address_uuid'].values[0]\n",
    "        else:\n",
    "            # If no, check if the part_street_district value has other occurrences in the part_street_district column\n",
    "            if row['part_street_district'] in addresses['part_street_district'].values:\n",
    "                # If yes, check if the part_street_district value is already in the uuid_dict\n",
    "                if row['part_street_district'] in uuid_dict:\n",
    "                    # If yes, assign the same uuid\n",
    "                    addresses.loc[i, 'part_street_district_uuid'] = uuid_dict[row['part_street_district']]\n",
    "                else:\n",
    "                    # If no, create a new uuid and add it to the uuid_dict\n",
    "                    new_uuid = uuid.uuid4()\n",
    "                    uuid_dict[row['part_street_district']] = new_uuid\n",
    "                    addresses.loc[i, 'part_street_district_uuid'] = new_uuid\n",
    "            else:\n",
    "                # If no, create a new uuid\n",
    "                addresses.loc[i, 'part_street_district_uuid'] = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RDF graph\n",
    "g = Graph()\n",
    "\n",
    "g.bind('landmark', landmarkuri)\n",
    "g.bind('source', srcuri)\n",
    "\n",
    "g.bind('cad', cad)\n",
    "g.bind('add', add)\n",
    "g.bind('rico', rico)\n",
    "g.bind('fpo', fpo)\n",
    "g.bind('time',time)\n",
    "\n",
    "g.bind(\"ltype\", ltype)\n",
    "g.bind(\"lrtype\", lrtype)\n",
    "g.bind(\"atype\", atype)\n",
    "g.bind('cad_ltype', cad_ltype)\n",
    "\n",
    "for index, row in addresses.iterrows():\n",
    "    add_uri = URIRef(landmarkuri + str(row['address_uuid']))\n",
    "    print(add_uri)\n",
    "    g.add((add_uri, RDF.type, add.Landmark))\n",
    "\n",
    "    if pd.notnull(addresses.loc[index, 'Lieu-dit_type']):\n",
    "        if ';' in row['Lieu-dit_treated']:\n",
    "            name = row['Lieu-dit_treated'].split(\";\")\n",
    "\n",
    "            g.add((add_uri, add.isLandmarkType, URIRef(ltype + row['part_street_number_type'])))\n",
    "\n",
    "            if any(num.isdigit() for num in name[1]):\n",
    "                g.add((add_uri, RDFS.label, Literal(name[1] + ' (' + name[0] + ', ' + COMMUNE + ')', datatype=XSD.string)))\n",
    "                relationode = BNode()\n",
    "                g.add((URIRef(relationode.n3()), add.isLandmarkRelationType, lrtype.Along))\n",
    "            else:\n",
    "                g.add((add_uri, RDFS.label, Literal(name[0] + ' (' + name[1] + ', ' + COMMUNE + ')', datatype=XSD.string)))\n",
    "                relationode = BNode()\n",
    "                g.add((URIRef(relationode.n3()), add.isLandmarkRelationType, lrtype.Undefined))\n",
    "\n",
    "            g.add((URIRef(relationode.n3()), RDF.type, add.LandmarkRelation))\n",
    "            g.add((URIRef(relationode.n3()), add.locatum, add_uri))\n",
    "            g.add((URIRef(relationode.n3()), add.relatum, URIRef(landmarkuri + str(row['part_street_district_uuid']))))\n",
    "\n",
    "            #Street or district relation with section\n",
    "            sectionNode = BNode()\n",
    "            g.add((URIRef(sectionNode.n3()), RDF.type, add.LandmarkRelation))\n",
    "            g.add((URIRef(sectionNode.n3()), add.isLandmarkRelationType, lrtype.Within))\n",
    "            g.add((URIRef(sectionNode.n3()), add.locatum, URIRef(landmarkuri + str(row['part_street_district_uuid']))))\n",
    "            if row['registre'] != 'MAT_1848':\n",
    "                g.add((URIRef(sectionNode.n3()), add.relatum, URIRef(landmarkuri + 'da6a5c2c-e86d-43bb-8950-7169bd0df60a'))) #Section D Cadastre 1848\n",
    "            else:\n",
    "                g.add((URIRef(sectionNode.n3()), add.relatum, URIRef(landmarkuri + '87d7c2f6-306b-45a1-a833-5e17821c3102'))) #Section B Cadastre 1811\n",
    "\n",
    "        else:\n",
    "            g.add((add_uri, add.isLandmarkType, URIRef(ltype + row['Lieu-dit_type'])))\n",
    "            g.add((add_uri, RDFS.label, Literal(row['Lieu-dit_treated'] + ', ' + COMMUNE, datatype=XSD.string)))\n",
    "\n",
    "            relationode = BNode()\n",
    "            g.add((URIRef(relationode.n3()), add.isLandmarkRelationType, lrtype.Within))\n",
    "            g.add((URIRef(relationode.n3()), add.locatum, add_uri))\n",
    "\n",
    "            sectionNode = BNode()\n",
    "            g.add((URIRef(sectionNode.n3()), RDF.type, add.LandmarkRelation))\n",
    "            g.add((URIRef(sectionNode.n3()), add.isLandmarkRelationType, lrtype.Within))\n",
    "            g.add((URIRef(sectionNode.n3()), add.locatum, add_uri))\n",
    "            if row['registre'] != 'MAT_1848':\n",
    "                g.add((URIRef(sectionNode.n3()), add.relatum, URIRef(landmarkuri + 'da6a5c2c-e86d-43bb-8950-7169bd0df60a'))) #Section D Cadastre 1848\n",
    "            else:\n",
    "                g.add((URIRef(sectionNode.n3()), add.relatum, URIRef(landmarkuri + '87d7c2f6-306b-45a1-a833-5e17821c3102'))) #Section B Cadastre 1811\n",
    "\n",
    "        g.add((add_uri, cad.sourcedFrom, URIRef(srcuri + f'94_{COMMUNE}_{row[\"registre\"]}')))\n",
    "\n",
    "\n",
    "print(g.serialize(format='turtle'))\n",
    "g.serialize(destination=f\"{OUTPUT_FOLDER_PATH}/{COMMUNE}_landmarks_lieu_dit.ttl\", format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join Address/District UUID to the main matrices table\n",
    "subaddresses = addresses[['address_uuid','registre','Lieu-dit_treated']].copy()\n",
    "#join subaddresses['uuid'] to matrices on ['registre','Lieu-dit_treated'] rename the column to 'address_uuid'\n",
    "matrices = pd.merge(matrices, subaddresses, how='left', left_on=['registre','Lieu-dit_treated'], right_on=['registre','Lieu-dit_treated'])\n",
    "matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Propriétaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners_df.columns\n",
    "owners_df['groupe_cf'] = owners_df['groupe_cf'].astype(str)\n",
    "matrices['Groupe CF'] = matrices['Groupe CF'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = matrices.merge(owners_df, how='left', right_on=[\"registre\",\"type_folio\",\"folio\",'groupe_cf'], left_on=[\"registre\",\"Type_CF\",\"Num_Folio\",\"Groupe CF\"])\n",
    "matrices = matrices.drop([\"type_folio\",\"folio\",'groupe_cf',\"transcription\",\"cell\"], axis=1).reset_index(drop=True)\n",
    "matrices['CF_uuid'] = [uuid.uuid4() for _ in range(len(matrices))]\n",
    "matrices['CF_uuid'] = matrices.groupby(['registre', 'Num_Folio_clean','Type_CF','Groupe CF'])['CF_uuid'].transform(lambda x: uuid.uuid4())\n",
    "matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Créer les comptes fonciers\n",
    "* Associer à chaque compte foncier ses propriétaires (ordonnés dans le temps)\n",
    "* Associer à chaque compte foncier le landmark (état) qu'il mentionne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RDF graph\n",
    "g = Graph()\n",
    "\n",
    "baseuri = Namespace(\"http://data.ign.fr/id/landmark/\")\n",
    "srcuri = Namespace(\"http://data.ign.fr/id/source/\")\n",
    "cad_ltype = Namespace(\"http://data.ign.fr/def/cadastre/landmarkType/\")\n",
    "cad_atype = Namespace(\"http://data.ign.fr/def/cadastre/attributeType/\")\n",
    "srctype = Namespace(\"http://data.ign.fr/id/codes/cadastre/sourceType/\")\n",
    "mlclasse= Namespace(\"http://data.ign.fr/id/codes/cadastre/mlClasse/\")\n",
    "\n",
    "g.bind('landmark', baseuri)\n",
    "g.bind('source', srcuri)\n",
    "g.bind('cad_ltype', cad_ltype)\n",
    "g.bind('srctype', srctype)\n",
    "g.bind('mlclasse', mlclasse)\n",
    "\n",
    "for index, row in matrices.iterrows():\n",
    "    json = parse_record_id(row[\"Image\"])\n",
    "    lineuuid_ = MATRICE_ID + '_' + str(row['ID']) #str(uuid.uuid4())\n",
    "\n",
    "    subject_uri = URIRef(srcuri + f\"{row['CF_uuid']}\")\n",
    "    g.add((subject_uri, RDF.type, rico.RecordPart))\n",
    "    g.add((subject_uri, cad.isSourceType, URIRef(srctype.CompteFoncier)))\n",
    "    g.add((subject_uri, rico.hasOrHadConstituent, Literal(srcuri + f\"{row['UUID']}\")))\n",
    "    g.add((subject_uri, rico.hasOrWasConstituentOf, URIRef(baseuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}_{str(row['Num_Folio_clean'])}\")))\n",
    "    g.add((subject_uri, rico.hasOrHadConstituent, Literal(srcuri + f\"{row['CF_uuid']}_mutations\")))\n",
    "\n",
    "    articlemutationuri = URIRef(srcuri + f\"{row['CF_uuid']}_mutations\")\n",
    "    g.add((articlemutationuri, RDF.type, rico.RecordPart))\n",
    "    g.add((articlemutationuri, cad.isSourceType, URIRef(srctype.ArticleDeMutation)))\n",
    "\n",
    "    ownersattribute = BNode()\n",
    "    g.add((ownersattribute, RDF.type, add.Attribute))\n",
    "    g.add((subject_uri, cad.hasCadastreAttribute, ownersattribute))\n",
    "    g.add((ownersattribute, add.hasAttributeType, URIRef(cad_atype.PlotTaxpayer)))\n",
    "    print(row['owners'])\n",
    "\n",
    "\n",
    "    articleclassementuri = URIRef(srcuri + f\"{row['UUID']}\")\n",
    "    g.add((articleclassementuri, RDF.type, rico.RecordPart))\n",
    "    g.add((articleclassementuri, cad.isSourceType, URIRef(srctype.ArticleDeClassement)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.X Création des états de parcelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RDF graph\n",
    "g = Graph()\n",
    "\n",
    "baseuri = Namespace(\"http://data.ign.fr/id/landmark/\")\n",
    "srcuri = Namespace(\"http://data.ign.fr/id/source/\")\n",
    "owneruri = Namespace(\"http://data.ign.fr/id/owner/\")\n",
    "\n",
    "cad_ltype = Namespace(\"http://data.ign.fr/id/codes/cadastre/landmarkType/\")\n",
    "cad_atype = Namespace(\"http://data.ign.fr/id/codes/cadastre/attributeType/\")\n",
    "lrtype = Namespace(\"http://rdf.geohistoricaldata.org/id/codes/address/landmarkRelationType/\")\n",
    "\n",
    "g.bind('landmark', baseuri)\n",
    "g.bind('owner', owneruri)\n",
    "g.bind('source', srcuri)\n",
    "g.bind('cad_ltype', cad_ltype)\n",
    "g.bind('cad_atype', cad_atype)\n",
    "\n",
    "# Define the namespaces\n",
    "cad = Namespace(\"http://data.ign.fr/def/cadastre#\")\n",
    "add = Namespace(\"http://rdf.geohistoricaldata.org/def/address#\")\n",
    "rico = Namespace(\"https://www.ica.org/standards/RiC/ontology#\")\n",
    "fpo = Namespace(\"https://github.com/johnBradley501/FPO/raw/master/fpo.owl#\")\n",
    "time = Namespace(\"http://www.w3.org/2006/time#\")\n",
    "\n",
    "g.bind('cad', cad)\n",
    "g.bind('add', add)\n",
    "g.bind('rico', rico)\n",
    "g.bind('fpo', fpo)\n",
    "g.bind('time',time)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in matrices.iterrows():\n",
    "\n",
    "    json = parse_record_id(row[\"Image\"])\n",
    "    MATRICE_ID = matrices_metada[row['registre']][\"MATRICE_ID\"]\n",
    "    PLAN = matrices_metada[row['registre']][\"PLAN\"]\n",
    "    lineuuid_ = MATRICE_ID + '_' + str(row['ID']) #str(uuid.uuid4())\n",
    "\n",
    "    subject_uri = URIRef(baseuri + f\"{row['UUID']}\")\n",
    "    g.add((subject_uri, RDF.type, add.Landmark))\n",
    "    g.add((subject_uri, add.isLandmarkType, cad_ltype.Plot))\n",
    "    #g.add((subject_uri, DCTERMS.identifier, Literal(row['Section_clean'] + '-' + row['Parcelle_clean'], datatype=XSD.string)))\n",
    "\n",
    "    #Folios\n",
    "    g.add((subject_uri, cad.hasNumFolio, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}_{str(row['Num_Folio'])}\")))\n",
    "    tire_de = str(row['Tiré de_treated']).split(',')\n",
    "    for f in tire_de:\n",
    "        if any(char.isdigit() for char in str(f)):\n",
    "            g.add((subject_uri, cad.takenFrom, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}_{str(f)}\")))\n",
    "        elif f != 'nan':\n",
    "            g.add((subject_uri, cad.takenFrom, Literal(str(f))))\n",
    "    porte_a = str(row['Porté à_treated']).split(',')\n",
    "    for f in porte_a:\n",
    "        if any(char.isdigit() for char in str(f)):\n",
    "            g.add((subject_uri, cad.passedTo, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}_{str(f)}\")))\n",
    "        elif f != 'nan':\n",
    "            g.add((subject_uri, cad.passedTo, Literal(str(f))))\n",
    "\n",
    "    #Source\n",
    "    rowSource = BNode()\n",
    "    g.add((subject_uri, fpo.sourcedFrom, rowSource))\n",
    "    g.add((rowSource, RDF.type, fpo.SourceCitation))\n",
    "    g.add((rowSource, fpo.fromSource, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{MATRICE_ID}\")))\n",
    "    g.add((rowSource, rico.isComponentOfTransitive, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{row['Image']}\")))\n",
    "    g.add((rowSource, cad.hasExtractionID, Literal(lineuuid_)))\n",
    "    g.add((rowSource, PROV.wasGeneratedBy, URIRef(f\"http://data.ign.fr/id/codes/cadastre/activity/0002\")))\n",
    "    g.add((URIRef(f\"http://data.ign.fr/id/codes/cadastre/activity/0002\"), PROV.used, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{row['Image']}\")))\n",
    "    g.add((rowSource, rico.isOrWasDigitalInstanciation,URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{row['Image']}_{lineuuid_}_area\")))\n",
    "    g.add((rowSource, cad.lineOrderInArea, Literal(row['Ordre de lecture'], datatype=XSD.integer)))\n",
    "\n",
    "    #Create recordpart\n",
    "    recordparturi = URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{row['Image']}_{lineuuid_}_area\")\n",
    "    g.add((recordparturi, RDF.type, rico.RecordPart))\n",
    "    g.add((recordparturi, rico.isOrWasIncludedIn, URIRef(srcuri + f\"{json['departement']}_{COMMUNE}_{row['Image']}_page\")))\n",
    "    \n",
    "    #Address\n",
    "    if row['Lieu-dit_treated'] != 'nan':\n",
    "        plotaddress = BNode()\n",
    "        g.add((subject_uri, add.hasAttribute, plotaddress))\n",
    "        g.add((plotaddress, add.isAttributeType, cad_atype.PlotAddress))\n",
    "        plotaddressversion = BNode()\n",
    "        g.add((plotaddress, add.hasAttributeVersion, plotaddressversion))\n",
    "        g.add((plotaddressversion, RDF.type, add.LandmarkRelation))\n",
    "        g.add((plotaddressversion, add.isLandmarkRelationType, lrtype.Undefined))\n",
    "        g.add((plotaddressversion, add.locatum, subject_uri))\n",
    "        g.add((plotaddressversion, add.relatum, URIRef(baseuri + str(row['address_uuid']))))\n",
    "\n",
    "    #Owner\n",
    "\n",
    "    #Nature\n",
    "    if not pd.isnull(row['Nature_treated']):\n",
    "        nature = BNode()\n",
    "        g.add((subject_uri, add.hasNature, nature))\n",
    "        g.add((nature, RDF.type, add.Nature))\n",
    "        g.add((nature, RDFS.label, Literal(row['Nature_treated'], datatype=XSD.string)))\n",
    "    \n",
    "    #Time\n",
    "    if not pd.isnull(row['Date entrée']) or not pd.isnull(['Date sortie']):\n",
    "        hastime = BNode()\n",
    "        g.add((subject_uri, add.hasTime, hastime))\n",
    "        g.add((hastime, RDF.type, add.TimeInterval))\n",
    "        \n",
    "        if not pd.isna(row['Date entrée']) and not pd.isnull(row['Date entrée']):\n",
    "            hasbeginning = BNode()\n",
    "            g.add((hastime, add.hasBeginning, hasbeginning))\n",
    "            g.add((hasbeginning,RDF.type, add.TimeInstant))\n",
    "            g.add((hasbeginning, add.timeCalendar, time.Gregorian))\n",
    "            g.add((hasbeginning, add.timePrecision, time.Year))\n",
    "            g.add((hasbeginning, add.timeStamp, Literal(row['Date entrée'], datatype=XSD.date)))\n",
    "        #else:\n",
    "            #g.add((hastime, add.hasBeginning, Literal(MATRICE_START, datatype=XSD.date)))#date d'ouverture de la matrice\n",
    "        if not pd.isnull(row['Date sortie']) and row['Date sortie'] != 'nan':\n",
    "            hasend = BNode()\n",
    "            g.add((hastime, add.hasBeginning, hasend))\n",
    "            g.add((hasend,RDF.type, add.TimeInstant))\n",
    "            g.add((hasend, add.timeCalendar, time.Gregorian))\n",
    "            g.add((hasend, add.timePrecision, time.Year))\n",
    "            g.add((hasend, add.timeStamp, Literal(row['Date entrée'], datatype=XSD.date)))\n",
    "print(g.serialize(format='turtle'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
